{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 1: Central Bank Reaction and Confidence Effects - Detailed Analysis\n",
    "\n",
    "This notebook provides an in-depth analysis of Hypothesis 1, which tests whether strong central bank reactions to debt service burdens combined with negative confidence effects create a threshold beyond which QE increases long-term yields.\n",
    "\n",
    "## Economic Theory\n",
    "\n",
    "The hypothesis is based on the idea that:\n",
    "\n",
    "1. **Central Bank Reaction (γ₁):** Strong policy responses to rising debt service burdens\n",
    "2. **Confidence Effects (λ₂):** Negative confidence effects that amplify policy transmission\n",
    "3. **Threshold Behavior:** Beyond a certain debt service threshold, the combination of strong reactions and negative confidence creates a regime where QE becomes counterproductive\n",
    "\n",
    "## Methodology\n",
    "\n",
    "We use Hansen's threshold regression model to detect structural breaks:\n",
    "\n",
    "$$y_t = \\alpha_1 + \\beta_1 X_t + \\epsilon_t \\quad \\text{if } q_t \\leq \\gamma$$\n",
    "$$y_t = \\alpha_2 + \\beta_2 X_t + \\epsilon_t \\quad \\text{if } q_t > \\gamma$$\n",
    "\n",
    "Where:\n",
    "- $y_t$ = Long-term yields (10Y Treasury)\n",
    "- $X_t$ = [Central bank reaction, Confidence effects, Interaction term]\n",
    "- $q_t$ = Debt service burden (threshold variable)\n",
    "- $\\gamma$ = Threshold parameter (estimated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# QEIR imports\n",
    "from qeir.core.hypothesis_testing import QEHypothesisTester, HypothesisTestingConfig\n",
    "from qeir.utils.hypothesis_data_collector import HypothesisDataCollector\n",
    "from qeir.core.models import HansenThresholdRegression\n",
    "\n",
    "# Plotting setup\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Hypothesis 1 Detailed Analysis - Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize framework (replace with your API key)\n",
    "import os\n",
    "FRED_API_KEY = os.getenv('FRED_API_KEY')\n",
    "if not FRED_API_KEY:\n",
    "    raise ValueError('FRED_API_KEY environment variable is required')\n",
    "\n",
    "collector = HypothesisDataCollector(fred_api_key=FRED_API_KEY)\n",
    "\n",
    "# Enhanced configuration for detailed analysis\n",
    "config = HypothesisTestingConfig(\n",
    "    start_date=\"2008-01-01\",\n",
    "    end_date=\"2023-12-31\",\n",
    "    confidence_level=0.95,\n",
    "    bootstrap_iterations=500,  # More iterations for better precision\n",
    "    h1_threshold_trim=0.15,\n",
    "    h1_min_regime_size=10,\n",
    "    h1_test_alternative_thresholds=True,\n",
    "    enable_robustness_tests=True\n",
    ")\n",
    "\n",
    "tester = QEHypothesisTester(data_collector=collector, config=config)\n",
    "print(\"Framework initialized for detailed Hypothesis 1 analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect Hypothesis 1 specific data\n",
    "print(\"Collecting Hypothesis 1 data...\")\n",
    "h1_data = collector.collect_hypothesis1_data(config.start_date, config.end_date)\n",
    "\n",
    "print(f\"\\nCollected {len(h1_data)} data series:\")\n",
    "for series_name, series in h1_data.items():\n",
    "    if series is not None and not series.empty:\n",
    "        print(f\"  {series_name}: {len(series)} observations ({series.index.min()} to {series.index.max()})\")\n",
    "    else:\n",
    "        print(f\"  {series_name}: No data\")\n",
    "\n",
    "# Validate data quality\n",
    "quality_report = collector.validate_data_quality(h1_data)\n",
    "print(f\"\\nData quality score: {quality_report['summary']['overall_quality_score']:.1f}/100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive data visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Key variables for Hypothesis 1\n",
    "key_vars = {\n",
    "    'fed_total_assets': 'Central Bank Reaction (Fed Assets, $T)',\n",
    "    'consumer_confidence': 'Confidence Effects (Consumer Sentiment)',\n",
    "    'federal_interest_payments': 'Debt Service Burden (Interest Payments)',\n",
    "    'treasury_10y': 'Long-term Yields (10Y Treasury, %)'\n",
    "}\n",
    "\n",
    "for i, (var_name, title) in enumerate(key_vars.items()):\n",
    "    row, col = i // 2, i % 2\n",
    "    \n",
    "    if var_name in h1_data and h1_data[var_name] is not None:\n",
    "        series = h1_data[var_name].dropna()\n",
    "        axes[row, col].plot(series.index, series.values, linewidth=2, color=f'C{i}')\n",
    "        axes[row, col].set_title(title, fontsize=12, fontweight='bold')\n",
    "        axes[row, col].grid(True, alpha=0.3)\n",
    "        axes[row, col].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add QE period shading\n",
    "        qe_periods = [\n",
    "            ('2008-11-01', '2010-06-30', 'QE1'),\n",
    "            ('2010-11-01', '2011-06-30', 'QE2'),\n",
    "            ('2012-09-01', '2014-10-31', 'QE3')\n",
    "        ]\n",
    "        \n",
    "        for start, end, label in qe_periods:\n",
    "            axes[row, col].axvspan(pd.to_datetime(start), pd.to_datetime(end), \n",
    "                                 alpha=0.2, color='red', label=label if i == 0 else \"\")\n",
    "    else:\n",
    "        axes[row, col].text(0.5, 0.5, 'Data Not Available', \n",
    "                          ha='center', va='center', transform=axes[row, col].transAxes)\n",
    "        axes[row, col].set_title(title, fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add legend for QE periods\n",
    "if 'fed_total_assets' in h1_data:\n",
    "    axes[0, 0].legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Hypothesis 1: Key Variables Over Time', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "print(\"Correlation Analysis of Key Variables:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create correlation matrix\n",
    "corr_data = {}\n",
    "for var_name, title in key_vars.items():\n",
    "    if var_name in h1_data and h1_data[var_name] is not None:\n",
    "        corr_data[title.split('(')[0].strip()] = h1_data[var_name]\n",
    "\n",
    "if len(corr_data) >= 2:\n",
    "    corr_df = pd.DataFrame(corr_data).dropna()\n",
    "    correlation_matrix = corr_df.corr()\n",
    "    \n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='RdBu_r', center=0, \n",
    "                square=True, fmt='.3f', cbar_kws={'label': 'Correlation Coefficient'})\n",
    "    plt.title('Correlation Matrix: Hypothesis 1 Variables', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nCorrelation Matrix:\")\n",
    "    print(correlation_matrix.round(3))\nelse:\n",
    "    print(\"Insufficient data for correlation analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Analysis Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for threshold analysis\n",
    "print(\"Preparing data for threshold analysis...\")\n",
    "\n",
    "# Load complete hypothesis data\n",
    "data = tester.load_data()\n",
    "\n",
    "# Extract key variables\n",
    "if (data.long_term_yields is not None and data.central_bank_reaction is not None and \n",
    "    data.confidence_effects is not None and data.debt_service_burden is not None):\n",
    "    \n",
    "    # Align data to common dates\n",
    "    common_dates = (data.long_term_yields.dropna().index\n",
    "                   .intersection(data.central_bank_reaction.dropna().index)\n",
    "                   .intersection(data.confidence_effects.dropna().index)\n",
    "                   .intersection(data.debt_service_burden.dropna().index))\n",
    "    \n",
    "    print(f\"Common observations: {len(common_dates)}\")\n",
    "    print(f\"Date range: {common_dates.min()} to {common_dates.max()}\")\n",
    "    \n",
    "    if len(common_dates) >= 50:\n",
    "        # Extract aligned series\n",
    "        y = data.long_term_yields.loc[common_dates]\n",
    "        cb_reaction = data.central_bank_reaction.loc[common_dates]\n",
    "        confidence = data.confidence_effects.loc[common_dates]\n",
    "        threshold_var = data.debt_service_burden.loc[common_dates]\n",
    "        \n",
    "        # Create interaction term\n",
    "        interaction = cb_reaction * confidence\n",
    "        \n",
    "        # Standardize variables for better numerical stability\n",
    "        cb_reaction_std = (cb_reaction - cb_reaction.mean()) / cb_reaction.std()\n",
    "        confidence_std = (confidence - confidence.mean()) / confidence.std()\n",
    "        interaction_std = (interaction - interaction.mean()) / interaction.std()\n",
    "        \n",
    "        print(\"\\nVariable Statistics:\")\n",
    "        print(f\"Long-term yields: {y.mean():.3f} ± {y.std():.3f}\")\n",
    "        print(f\"Central bank reaction: {cb_reaction.mean():.1f} ± {cb_reaction.std():.1f}\")\n",
    "        print(f\"Confidence effects: {confidence.mean():.1f} ± {confidence.std():.1f}\")\n",
    "        print(f\"Debt service burden: {threshold_var.mean():.1f} ± {threshold_var.std():.1f}\")\n",
    "        \n",
    "        data_ready = True\n",
    "    else:\n",
    "        print(\"Insufficient overlapping data for analysis\")\n",
    "        data_ready = False\nelse:\n",
    "    print(\"Required data series not available\")\n",
    "    data_ready = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Detection and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_ready:\n",
    "    # Visualize threshold variable vs dependent variable\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Scatter plot: Threshold variable vs Long-term yields\n",
    "    axes[0].scatter(threshold_var, y, alpha=0.6, s=50)\n",
    "    axes[0].set_xlabel('Debt Service Burden')\n",
    "    axes[0].set_ylabel('Long-term Yields (%)')\n",
    "    axes[0].set_title('Threshold Variable vs Dependent Variable')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(threshold_var, y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[0].plot(threshold_var, p(threshold_var), \"r--\", alpha=0.8, linewidth=2)\n",
    "    \n",
    "    # Time series plot with threshold variable\n",
    "    ax1 = axes[1]\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    line1 = ax1.plot(common_dates, y, 'b-', linewidth=2, label='Long-term Yields')\n",
    "    line2 = ax2.plot(common_dates, threshold_var, 'r-', linewidth=2, alpha=0.7, label='Debt Service Burden')\n",
    "    \n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Long-term Yields (%)', color='b')\n",
    "    ax2.set_ylabel('Debt Service Burden', color='r')\n",
    "    ax1.tick_params(axis='y', labelcolor='b')\n",
    "    ax2.tick_params(axis='y', labelcolor='r')\n",
    "    ax1.set_title('Time Series: Yields and Threshold Variable')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Combined legend\n",
    "    lines = line1 + line2\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax1.legend(lines, labels, loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Distribution of threshold variable\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(threshold_var, bins=20, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Debt Service Burden')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Threshold Variable')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    stats.probplot(threshold_var, dist=\"norm\", plot=plt)\n",
    "    plt.title('Q-Q Plot: Threshold Variable Normality')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\nelse:\n",
    "    print(\"Cannot proceed with threshold analysis due to data issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hansen Threshold Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_ready:\n",
    "    print(\"Running Hansen Threshold Regression...\")\n",
    "    \n",
    "    # Run the full hypothesis test\n",
    "    h1_results = tester.test_hypothesis1(data)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"HANSEN THRESHOLD REGRESSION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if 'error' not in h1_results.main_result:\n",
    "        main_result = h1_results.main_result\n",
    "        stat_sig = h1_results.statistical_significance\n",
    "        \n",
    "        print(f\"\\nModel Status: {'✓ FITTED' if main_result.get('threshold_detected') else '✗ NO THRESHOLD'}\")\n",
    "        print(f\"Observations: {h1_results.data_period.get('observations')}\")\n",
    "        print(f\"Sample Period: {h1_results.data_period.get('start_date')} to {h1_results.data_period.get('end_date')}\")\n",
    "        \n",
    "        if main_result.get('threshold_detected'):\n",
    "            print(f\"\\nThreshold Estimate: {main_result.get('threshold_value'):.4f}\")\n",
    "            print(f\"Regime 1 Observations: {main_result.get('regime1_observations')} ({main_result.get('regime1_observations')/h1_results.data_period.get('observations', 1)*100:.1f}%)\")\n",
    "            print(f\"Regime 2 Observations: {main_result.get('regime2_observations')} ({main_result.get('regime2_observations')/h1_results.data_period.get('observations', 1)*100:.1f}%)\")\n",
    "            \n",
    "            print(f\"\\nModel Fit:\")\n",
    "            print(f\"Overall R²: {main_result.get('overall_r2', 0):.4f}\")\n",
    "            print(f\"Regime 1 R²: {main_result.get('regime1_r2', 0):.4f}\")\n",
    "            print(f\"Regime 2 R²: {main_result.get('regime2_r2', 0):.4f}\")\n",
    "            \n",
    "            if stat_sig:\n",
    "                print(f\"\\nStructural Break Test:\")\n",
    "                print(f\"F-statistic: {stat_sig.get('structural_break_fstat', 0):.4f}\")\n",
    "                print(f\"P-value: {stat_sig.get('structural_break_pvalue', 1):.4f}\")\n",
    "                print(f\"Significant at 5%: {'Yes' if stat_sig.get('structural_break_significant', False) else 'No'}\")\n",
    "            \n",
    "            # Extract detailed model results if available\n",
    "            if h1_results.model_results.hansen_results:\n",
    "                hansen_res = h1_results.model_results.hansen_results\n",
    "                \n",
    "                if 'regime1_coefficients' in hansen_res and 'regime2_coefficients' in hansen_res:\n",
    "                    print(f\"\\nRegime Coefficients:\")\n",
    "                    print(f\"Regime 1 (Below Threshold):\")\n",
    "                    coef_names = ['Constant', 'CB Reaction', 'Confidence', 'Interaction']\n",
    "                    for i, (name, coef) in enumerate(zip(coef_names, hansen_res['regime1_coefficients'])):\n",
    "                        se = hansen_res.get('regime1_std_errors', [0]*len(coef_names))[i]\n",
    "                        print(f\"  {name}: {coef:.4f} (SE: {se:.4f})\")\n",
    "                    \n",
    "                    print(f\"\\nRegime 2 (Above Threshold):\")\n",
    "                    for i, (name, coef) in enumerate(zip(coef_names, hansen_res['regime2_coefficients'])):\n",
    "                        se = hansen_res.get('regime2_std_errors', [0]*len(coef_names))[i]\n",
    "                        print(f\"  {name}: {coef:.4f} (SE: {se:.4f})\")\n",
    "        else:\n",
    "            print(\"\\nNo significant threshold detected.\")\n",
    "            print(\"The relationship appears to be linear across the sample.\")\n",
    "    else:\n",
    "        print(f\"\\n✗ Analysis failed: {h1_results.main_result['error']}\")\nelse:\n",
    "    print(\"Cannot run Hansen regression due to data preparation issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Visualization and Regime Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_ready and 'h1_results' in locals() and 'error' not in h1_results.main_result:\n",
    "    if h1_results.main_result.get('threshold_detected'):\n",
    "        threshold_value = h1_results.main_result.get('threshold_value')\n",
    "        \n",
    "        # Create regime-based visualization\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # Regime classification\n",
    "        regime1_mask = threshold_var <= threshold_value\n",
    "        regime2_mask = threshold_var > threshold_value\n",
    "        \n",
    "        # Plot 1: Scatter plot with regime coloring\n",
    "        axes[0, 0].scatter(threshold_var[regime1_mask], y[regime1_mask], \n",
    "                          alpha=0.7, s=50, color='blue', label=f'Regime 1 (≤{threshold_value:.3f})')\n",
    "        axes[0, 0].scatter(threshold_var[regime2_mask], y[regime2_mask], \n",
    "                          alpha=0.7, s=50, color='red', label=f'Regime 2 (>{threshold_value:.3f})')\n",
    "        axes[0, 0].axvline(threshold_value, color='black', linestyle='--', linewidth=2, label='Threshold')\n",
    "        axes[0, 0].set_xlabel('Debt Service Burden')\n",
    "        axes[0, 0].set_ylabel('Long-term Yields (%)')\n",
    "        axes[0, 0].set_title('Threshold Regression: Regime Classification')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Time series with regime shading\n",
    "        axes[0, 1].plot(common_dates, y, 'k-', linewidth=2, label='Long-term Yields')\n",
    "        \n",
    "        # Shade regime periods\n",
    "        for i in range(len(common_dates)):\n",
    "            if regime1_mask.iloc[i]:\n",
    "                axes[0, 1].axvspan(common_dates[i], common_dates[i], alpha=0.3, color='blue')\n",
    "            else:\n",
    "                axes[0, 1].axvspan(common_dates[i], common_dates[i], alpha=0.3, color='red')\n",
    "        \n",
    "        axes[0, 1].set_xlabel('Date')\n",
    "        axes[0, 1].set_ylabel('Long-term Yields (%)')\n",
    "        axes[0, 1].set_title('Time Series with Regime Classification')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: Threshold variable over time\n",
    "        axes[1, 0].plot(common_dates, threshold_var, 'g-', linewidth=2)\n",
    "        axes[1, 0].axhline(threshold_value, color='black', linestyle='--', linewidth=2, label='Threshold')\n",
    "        axes[1, 0].fill_between(common_dates, threshold_var.min(), threshold_value, \n",
    "                               alpha=0.3, color='blue', label='Regime 1')\n",
    "        axes[1, 0].fill_between(common_dates, threshold_value, threshold_var.max(), \n",
    "                               alpha=0.3, color='red', label='Regime 2')\n",
    "        axes[1, 0].set_xlabel('Date')\n",
    "        axes[1, 0].set_ylabel('Debt Service Burden')\n",
    "        axes[1, 0].set_title('Threshold Variable Over Time')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 4: Regime statistics\n",
    "        regime_stats = pd.DataFrame({\n",
    "            'Regime 1': [\n",
    "                y[regime1_mask].mean(),\n",
    "                cb_reaction[regime1_mask].mean(),\n",
    "                confidence[regime1_mask].mean(),\n",
    "                interaction[regime1_mask].mean()\n",
    "            ],\n",
    "            'Regime 2': [\n",
    "                y[regime2_mask].mean(),\n",
    "                cb_reaction[regime2_mask].mean(),\n",
    "                confidence[regime2_mask].mean(),\n",
    "                interaction[regime2_mask].mean()\n",
    "            ]\n",
    "        }, index=['Yields', 'CB Reaction', 'Confidence', 'Interaction'])\n",
    "        \n",
    "        regime_stats.plot(kind='bar', ax=axes[1, 1], color=['blue', 'red'], alpha=0.7)\n",
    "        axes[1, 1].set_title('Average Values by Regime')\n",
    "        axes[1, 1].set_ylabel('Average Value')\n",
    "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.suptitle('Hypothesis 1: Threshold Analysis Results', fontsize=16, fontweight='bold', y=1.02)\n",
    "        plt.show()\n",
    "        \n",
    "        # Print regime statistics\n",
    "        print(\"\\nRegime Statistics:\")\n",
    "        print(\"=\" * 40)\n",
    "        print(regime_stats.round(3))\n",
    "        \n",
    "        print(f\"\\nRegime Transition Dates:\")\n",
    "        regime_changes = []\n",
    "        current_regime = 1 if regime1_mask.iloc[0] else 2\n",
    "        \n",
    "        for i in range(1, len(regime1_mask)):\n",
    "            new_regime = 1 if regime1_mask.iloc[i] else 2\n",
    "            if new_regime != current_regime:\n",
    "                regime_changes.append((common_dates[i], current_regime, new_regime))\n",
    "                current_regime = new_regime\n",
    "        \n",
    "        if regime_changes:\n",
    "            for date, from_regime, to_regime in regime_changes[:10]:  # Show first 10 transitions\n",
    "                print(f\"  {date.strftime('%Y-%m-%d')}: Regime {from_regime} → Regime {to_regime}\")\n",
    "            if len(regime_changes) > 10:\n",
    "                print(f\"  ... and {len(regime_changes) - 10} more transitions\")\n",
    "        else:\n",
    "            print(\"  No regime transitions detected\")\n",
    "    else:\n",
    "        print(\"No threshold detected - cannot create regime visualizations\")\nelse:\n",
    "    print(\"Cannot create threshold visualizations due to analysis issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Economic Interpretation and Policy Implications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_ready and 'h1_results' in locals() and 'error' not in h1_results.main_result:\n",
    "    print(\"ECONOMIC INTERPRETATION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if h1_results.main_result.get('threshold_detected'):\n",
    "        threshold_value = h1_results.main_result.get('threshold_value')\n",
    "        \n",
    "        print(f\"\\n1. THRESHOLD IDENTIFICATION:\")\n",
    "        print(f\"   • Debt service threshold: {threshold_value:.4f}\")\n",
    "        print(f\"   • This represents the critical level where QE transmission changes\")\n",
    "        \n",
    "        if h1_results.statistical_significance.get('structural_break_significant'):\n",
    "            print(f\"   • The threshold is statistically significant (p < 0.05)\")\n",
    "        else:\n",
    "            print(f\"   • The threshold is not statistically significant\")\n",
    "        \n",
    "        print(f\"\\n2. REGIME CHARACTERISTICS:\")\n",
    "        regime1_obs = h1_results.main_result.get('regime1_observations', 0)\n",
    "        regime2_obs = h1_results.main_result.get('regime2_observations', 0)\n",
    "        total_obs = regime1_obs + regime2_obs\n",
    "        \n",
    "        print(f\"   • Regime 1 (Low debt service): {regime1_obs} observations ({regime1_obs/total_obs*100:.1f}%)\")\n",
    "        print(f\"   • Regime 2 (High debt service): {regime2_obs} observations ({regime2_obs/total_obs*100:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\n3. POLICY IMPLICATIONS:\")\n",
    "        print(f\"   • When debt service burden is below {threshold_value:.4f}:\")\n",
    "        print(f\"     - QE transmission follows 'normal' patterns\")\n",
    "        print(f\"     - Central bank reactions and confidence effects work as expected\")\n",
    "        \n",
    "        print(f\"   • When debt service burden exceeds {threshold_value:.4f}:\")\n",
    "        print(f\"     - QE transmission may become counterproductive\")\n",
    "        print(f\"     - Strong central bank reactions combined with negative confidence\")\n",
    "        print(f\"       effects may increase rather than decrease long-term yields\")\n",
    "        \n",
    "        print(f\"\\n4. HISTORICAL CONTEXT:\")\n",
    "        if 'regime_changes' in locals() and regime_changes:\n",
    "            print(f\"   • The economy switched between regimes {len(regime_changes)} times\")\n",
    "            print(f\"   • This suggests the threshold mechanism is active and relevant\")\n",
    "        \n",
    "        # Calculate time spent in each regime\n",
    "        if data_ready:\n",
    "            regime1_pct = (regime1_mask.sum() / len(regime1_mask)) * 100\n",
    "            regime2_pct = (regime2_mask.sum() / len(regime2_mask)) * 100\n",
    "            \n",
    "            print(f\"   • Time in Regime 1: {regime1_pct:.1f}% of sample period\")\n",
    "            print(f\"   • Time in Regime 2: {regime2_pct:.1f}% of sample period\")\n",
    "        \n",
    "        print(f\"\\n5. ROBUSTNESS AND LIMITATIONS:\")\n",
    "        print(f\"   • Model R²: {h1_results.main_result.get('overall_r2', 0):.4f}\")\n",
    "        print(f\"   • Results depend on data quality and model specification\")\n",
    "        print(f\"   • Threshold may vary with different economic conditions\")\n",
    "        print(f\"   • Consider alternative confidence and reaction measures\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\n1. NO THRESHOLD DETECTED:\")\n",
    "        print(f\"   • The relationship between variables appears linear\")\n",
    "        print(f\"   • No evidence of regime-switching behavior\")\n",
    "        print(f\"   • QE transmission may be stable across debt service levels\")\n",
    "        \n",
    "        print(f\"\\n2. POSSIBLE EXPLANATIONS:\")\n",
    "        print(f\"   • Debt service burden may not be the correct threshold variable\")\n",
    "        print(f\"   • Threshold effects may be too subtle to detect\")\n",
    "        print(f\"   • Sample period may not include sufficient variation\")\n",
    "        print(f\"   • Other factors may dominate the relationship\")\n",
    "        \n",
    "        print(f\"\\n3. ALTERNATIVE APPROACHES:\")\n",
    "        print(f\"   • Try different threshold variables (e.g., debt-to-GDP ratio)\")\n",
    "        print(f\"   • Use alternative confidence measures\")\n",
    "        print(f\"   • Consider time-varying parameters\")\n",
    "        print(f\"   • Examine sub-periods separately\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 50)\nelse:\n",
    "    print(\"Cannot provide economic interpretation due to analysis issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness Tests and Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.enable_robustness_tests and 'h1_results' in locals():\n",
    "    print(\"ROBUSTNESS TESTS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Run robustness tests\n",
    "    print(\"Running robustness tests...\")\n",
    "    robustness_results = tester.run_robustness_tests({'hypothesis1': h1_results})\n",
    "    \n",
    "    if robustness_results:\n",
    "        print(\"\\n✓ Robustness tests completed\")\n",
    "        \n",
    "        # Alternative periods\n",
    "        if 'alternative_periods' in robustness_results:\n",
    "            print(\"\\nAlternative Time Periods:\")\n",
    "            for period_name, period_results in robustness_results['alternative_periods'].items():\n",
    "                if 'error' not in period_results:\n",
    "                    fitted = period_results.get('hypothesis1_fitted', False)\n",
    "                    threshold = period_results.get('threshold_value', 'N/A')\n",
    "                    obs = period_results.get('observations', 'N/A')\n",
    "                    period = period_results.get('period', 'Unknown')\n",
    "                    \n",
    "                    status = \"✓\" if fitted else \"✗\"\n",
    "                    print(f\"  {status} {period}: Threshold={threshold}, Obs={obs}\")\n",
    "                else:\n",
    "                    print(f\"  ✗ {period_results.get('period', 'Unknown')}: {period_results['error']}\")\n",
    "        \n",
    "        # Alternative specifications\n",
    "        if 'alternative_specifications' in robustness_results:\n",
    "            print(\"\\nAlternative Specifications:\")\n",
    "            for spec_name, spec_results in robustness_results['alternative_specifications'].items():\n",
    "                print(f\"  • {spec_name}: {spec_results.get('specification', 'Unknown')}\")\n",
    "    else:\n",
    "        print(\"No robustness test results available\")\n",
    "    \n",
    "    # Manual sensitivity analysis\n",
    "    print(\"\\nSensitivity Analysis:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    if data_ready:\n",
    "        # Test different trimming parameters\n",
    "        trim_values = [0.10, 0.15, 0.20, 0.25]\n",
    "        sensitivity_results = []\n",
    "        \n",
    "        for trim in trim_values:\n",
    "            try:\n",
    "                temp_config = HypothesisTestingConfig(\n",
    "                    start_date=config.start_date,\n",
    "                    end_date=config.end_date,\n",
    "                    h1_threshold_trim=trim,\n",
    "                    bootstrap_iterations=50,  # Reduced for speed\n",
    "                    enable_robustness_tests=False\n",
    "                )\n",
    "                \n",
    "                temp_tester = QEHypothesisTester(data_collector=collector, config=temp_config)\n",
    "                temp_results = temp_tester.test_hypothesis1(data)\n",
    "                \n",
    "                if 'error' not in temp_results.main_result:\n",
    "                    threshold_detected = temp_results.main_result.get('threshold_detected', False)\n",
    "                    threshold_value = temp_results.main_result.get('threshold_value', 'N/A')\n",
    "                    \n",
    "                    sensitivity_results.append({\n",
    "                        'trim': trim,\n",
    "                        'threshold_detected': threshold_detected,\n",
    "                        'threshold_value': threshold_value\n",
    "                    })\n",
    "                    \n",
    "                    status = \"✓\" if threshold_detected else \"✗\"\n",
    "                    print(f\"  Trim {trim:.2f}: {status} Threshold = {threshold_value}\")\n",
    "                else:\n",
    "                    print(f\"  Trim {trim:.2f}: ✗ Failed\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  Trim {trim:.2f}: ✗ Error - {str(e)[:50]}...\")\n",
    "        \n",
    "        # Summary of sensitivity\n",
    "        if sensitivity_results:\n",
    "            detected_count = sum(1 for r in sensitivity_results if r['threshold_detected'])\n",
    "            print(f\"\\nSensitivity Summary:\")\n",
    "            print(f\"  Threshold detected in {detected_count}/{len(sensitivity_results)} specifications\")\n",
    "            \n",
    "            if detected_count > 0:\n",
    "                threshold_values = [r['threshold_value'] for r in sensitivity_results if r['threshold_detected']]\n",
    "                if threshold_values and all(isinstance(tv, (int, float)) for tv in threshold_values):\n",
    "                    print(f\"  Threshold range: {min(threshold_values):.4f} to {max(threshold_values):.4f}\")\n",
    "                    print(f\"  Average threshold: {np.mean(threshold_values):.4f}\")\nelse:\n",
    "    print(\"Robustness tests disabled in configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HYPOTHESIS 1 - SUMMARY AND CONCLUSIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'h1_results' in locals() and 'error' not in h1_results.main_result:\n",
    "    print(f\"\\n📊 ANALYSIS SUMMARY:\")\n",
    "    print(f\"   • Sample Period: {h1_results.data_period.get('start_date')} to {h1_results.data_period.get('end_date')}\")\n",
    "    print(f\"   • Observations: {h1_results.data_period.get('observations')}\")\n",
    "    print(f\"   • Method: Hansen Threshold Regression\")\n",
    "    print(f\"   • Bootstrap Iterations: {config.bootstrap_iterations}\")\n",
    "    \n",
    "    threshold_detected = h1_results.main_result.get('threshold_detected', False)\n",
    "    \n",
    "    if threshold_detected:\n",
    "        print(f\"\\n✅ KEY FINDINGS:\")\n",
    "        print(f\"   • Threshold Effect: DETECTED\")\n",
    "        print(f\"   • Threshold Value: {h1_results.main_result.get('threshold_value'):.4f}\")\n",
    "        print(f\"   • Statistical Significance: {'Yes' if h1_results.statistical_significance.get('structural_break_significant') else 'No'}\")\n",
    "        print(f\"   • Model Fit (R²): {h1_results.main_result.get('overall_r2', 0):.4f}\")\n",
    "        \n",
    "        print(f\"\\n🎯 ECONOMIC IMPLICATIONS:\")\n",
    "        print(f\"   • QE transmission exhibits non-linear behavior\")\n",
    "        print(f\"   • Debt service burden acts as a critical threshold\")\n",
    "        print(f\"   • Policy effectiveness depends on fiscal conditions\")\n",
    "        print(f\"   • Confidence effects amplify threshold behavior\")\n",
    "        \n",
    "        print(f\"\\n⚠️  POLICY WARNINGS:\")\n",
    "        print(f\"   • QE may become counterproductive above threshold\")\n",
    "        print(f\"   • Monitor debt service burden carefully\")\n",
    "        print(f\"   • Consider fiscal-monetary policy coordination\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\n❌ KEY FINDINGS:\")\n",
    "        print(f\"   • Threshold Effect: NOT DETECTED\")\n",
    "        print(f\"   • Relationship appears linear\")\n",
    "        print(f\"   • No evidence of regime switching\")\n",
    "        \n",
    "        print(f\"\\n🤔 POSSIBLE EXPLANATIONS:\")\n",
    "        print(f\"   • Threshold variable may be incorrect\")\n",
    "        print(f\"   • Effects may be too subtle to detect\")\n",
    "        print(f\"   • Sample period limitations\")\n",
    "        print(f\"   • Model specification issues\")\n",
    "        \n",
    "        print(f\"\\n🔄 RECOMMENDATIONS:\")\n",
    "        print(f\"   • Try alternative threshold variables\")\n",
    "        print(f\"   • Use different confidence measures\")\n",
    "        print(f\"   • Extend sample period if possible\")\n",
    "        print(f\"   • Consider alternative methodologies\")\n",
    "    \n",
    "    print(f\"\\n📈 DATA QUALITY:\")\n",
    "    if 'quality_report' in locals():\n",
    "        print(f\"   • Overall Quality Score: {quality_report['summary']['overall_quality_score']:.1f}/100\")\n",
    "        print(f\"   • Critical Issues: {quality_report['summary']['critical_issues']}\")\n",
    "        print(f\"   • Data Reliability: {'High' if quality_report['summary']['overall_quality_score'] > 80 else 'Medium' if quality_report['summary']['overall_quality_score'] > 60 else 'Low'}\")\n",
    "    \n",
    "    print(f\"\\n🔬 ROBUSTNESS:\")\n",
    "    if config.enable_robustness_tests:\n",
    "        print(f\"   • Robustness tests: COMPLETED\")\n",
    "        print(f\"   • Alternative periods tested\")\n",
    "        print(f\"   • Sensitivity analysis performed\")\n",
    "    else:\n",
    "        print(f\"   • Robustness tests: SKIPPED (for speed)\")\n",
    "        print(f\"   • Enable for full analysis\")\n",
    "    \n",
    "    print(f\"\\n📚 NEXT STEPS:\")\n",
    "    print(f\"   1. Review results in context of economic theory\")\n",
    "    print(f\"   2. Compare with existing literature\")\n",
    "    print(f\"   3. Consider policy implications\")\n",
    "    print(f\"   4. Proceed to Hypothesis 2 and 3 testing\")\n",
    "    print(f\"   5. Generate publication-ready outputs\")\n",
    "    \nelse:\n",
    "    print(f\"\\n❌ ANALYSIS FAILED\")\n",
    "    if 'h1_results' in locals():\n",
    "        print(f\"   Error: {h1_results.main_result.get('error', 'Unknown error')}\")\n",
    "    else:\n",
    "        print(f\"   Could not complete analysis due to data issues\")\n",
    "    \n",
    "    print(f\"\\n🔧 TROUBLESHOOTING:\")\n",
    "    print(f\"   • Check FRED API key\")\n",
    "    print(f\"   • Verify internet connection\")\n",
    "    print(f\"   • Review data quality issues\")\n",
    "    print(f\"   • Try shorter time period\")\n",
    "    print(f\"   • Reduce bootstrap iterations\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"Hypothesis 1 detailed analysis completed.\")\n",
    "print(f\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}