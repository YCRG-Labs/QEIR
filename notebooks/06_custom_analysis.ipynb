{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QEIR Framework - Custom Analysis Examples\n",
    "\n",
    "This notebook demonstrates how to create custom analyses using the QEIR framework, including:\n",
    "\n",
    "1. **Custom Data Integration**\n",
    "2. **Alternative Model Specifications**\n",
    "3. **Custom Visualization and Reporting**\n",
    "4. **Integration with External Tools**\n",
    "5. **Publication-Ready Output Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from qeir.core.hypothesis_testing import QEHypothesisTester, HypothesisTestingConfig\n",
    "from qeir.utils.hypothesis_data_collector import HypothesisDataCollector\n",
    "from qeir.utils.data_structures import HypothesisData\n",
    "from qeir.visualization.publication_visualization import PublicationVisualizationSuite\n",
    "from qeir.utils.latex_table_generator import LaTeXTableGenerator\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "\n",
    "print(\"Custom Analysis Examples - Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Custom Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Creating custom HypothesisData with your own data\n",
    "def create_custom_hypothesis_data(start_date='2008-01-01', end_date='2023-12-31'):\n",
    "    \"\"\"\n",
    "    Create custom HypothesisData object with synthetic or external data\n",
    "    \"\"\"\n",
    "    # Create date range\n",
    "    dates = pd.date_range(start=start_date, end=end_date, freq='M')\n",
    "    n_obs = len(dates)\n",
    "    \n",
    "    # Generate synthetic data (replace with your actual data)\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    \n",
    "    # Hypothesis 1 data\n",
    "    central_bank_reaction = pd.Series(\n",
    "        1000 + 500 * np.random.randn(n_obs).cumsum() + 2000 * (dates.year >= 2008),\n",
    "        index=dates, name='central_bank_reaction'\n",
    "    )\n",
    "    \n",
    "    confidence_effects = pd.Series(\n",
    "        80 + 10 * np.random.randn(n_obs) - 20 * (dates.year >= 2008) * (dates.year <= 2010),\n",
    "        index=dates, name='confidence_effects'\n",
    "    )\n",
    "    \n",
    "    debt_service_burden = pd.Series(\n",
    "        200 + 50 * np.random.randn(n_obs) + 100 * (dates.year >= 2008),\n",
    "        index=dates, name='debt_service_burden'\n",
    "    )\n",
    "    \n",
    "    long_term_yields = pd.Series(\n",
    "        3.0 + 1.5 * np.random.randn(n_obs) - 2.0 * (dates.year >= 2008),\n",
    "        index=dates, name='long_term_yields'\n",
    "    )\n",
    "    \n",
    "    # Hypothesis 2 data\n",
    "    qe_intensity = pd.Series(\n",
    "        0.1 + 0.05 * np.random.randn(n_obs) + 0.3 * (dates.year >= 2008),\n",
    "        index=dates, name='qe_intensity'\n",
    "    )\n",
    "    \n",
    "    private_investment = pd.Series(\n",
    "        1000 + 100 * np.random.randn(n_obs) - 200 * (dates.year >= 2008) * (dates.year <= 2010),\n",
    "        index=dates, name='private_investment'\n",
    "    )\n",
    "    \n",
    "    market_distortions = pd.Series(\n",
    "        2.0 + 0.5 * np.random.randn(n_obs) + 1.0 * (dates.year >= 2008),\n",
    "        index=dates, name='market_distortions'\n",
    "    )\n",
    "    \n",
    "    interest_rate_channel = pd.Series(\n",
    "        4.0 + 1.0 * np.random.randn(n_obs) - 3.0 * (dates.year >= 2008),\n",
    "        index=dates, name='interest_rate_channel'\n",
    "    )\n",
    "    \n",
    "    # Hypothesis 3 data\n",
    "    foreign_bond_holdings = pd.Series(\n",
    "        5000 + 500 * np.random.randn(n_obs) + 1000 * (dates.year >= 2008),\n",
    "        index=dates, name='foreign_bond_holdings'\n",
    "    )\n",
    "    \n",
    "    exchange_rate = pd.Series(\n",
    "        100 + 10 * np.random.randn(n_obs) + 5 * (dates.year >= 2008),\n",
    "        index=dates, name='exchange_rate'\n",
    "    )\n",
    "    \n",
    "    inflation_measures = pd.Series(\n",
    "        2.0 + 0.5 * np.random.randn(n_obs) - 1.0 * (dates.year >= 2008) * (dates.year <= 2010),\n",
    "        index=dates, name='inflation_measures'\n",
    "    )\n",
    "    \n",
    "    capital_flows = pd.Series(\n",
    "        100 + 50 * np.random.randn(n_obs) - 100 * (dates.year >= 2008) * (dates.year <= 2010),\n",
    "        index=dates, name='capital_flows'\n",
    "    )\n",
    "    \n",
    "    # Create HypothesisData object\n",
    "    custom_data = HypothesisData()\n",
    "    custom_data.central_bank_reaction = central_bank_reaction\n",
    "    custom_data.confidence_effects = confidence_effects\n",
    "    custom_data.debt_service_burden = debt_service_burden\n",
    "    custom_data.long_term_yields = long_term_yields\n",
    "    custom_data.qe_intensity = qe_intensity\n",
    "    custom_data.private_investment = private_investment\n",
    "    custom_data.market_distortions = market_distortions\n",
    "    custom_data.interest_rate_channel = interest_rate_channel\n",
    "    custom_data.foreign_bond_holdings = foreign_bond_holdings\n",
    "    custom_data.exchange_rate = exchange_rate\n",
    "    custom_data.inflation_measures = inflation_measures\n",
    "    custom_data.capital_flows = capital_flows\n",
    "    custom_data.dates = dates\n",
    "    \n",
    "    custom_data.metadata = {\n",
    "        'source': 'custom_synthetic_data',\n",
    "        'creation_timestamp': datetime.now().isoformat(),\n",
    "        'start_date': start_date,\n",
    "        'end_date': end_date,\n",
    "        'observations': n_obs,\n",
    "        'frequency': 'monthly'\n",
    "    }\n",
    "    \n",
    "    return custom_data\n",
    "\n",
    "# Create custom data\n",
    "custom_data = create_custom_hypothesis_data()\n",
    "print(f\"Created custom data with {len(custom_data.dates)} observations\")\n",
    "print(f\"Date range: {custom_data.dates.min()} to {custom_data.dates.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom Analysis with Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis with custom data\n",
    "config = HypothesisTestingConfig(\n",
    "    bootstrap_iterations=100,  # Reduced for demonstration\n",
    "    enable_robustness_tests=False\n",
    ")\n",
    "\n",
    "# Initialize tester (no data collector needed for custom data)\n",
    "tester = QEHypothesisTester(config=config)\n",
    "\n",
    "# Test all hypotheses with custom data\n",
    "print(\"Testing hypotheses with custom data...\")\n",
    "\n",
    "h1_results = tester.test_hypothesis1(custom_data)\n",
    "h2_results = tester.test_hypothesis2(custom_data)\n",
    "h3_results = tester.test_hypothesis3(custom_data)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nCustom Data Analysis Results:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for i, (name, results) in enumerate([\n",
    "    ('Hypothesis 1', h1_results),\n",
    "    ('Hypothesis 2', h2_results),\n",
    "    ('Hypothesis 3', h3_results)\n",
    "], 1):\n",
    "    print(f\"\\n{name}:\")\n",
    "    if 'error' not in results.main_result:\n",
    "        print(f\"  âœ“ Analysis completed\")\n",
    "        print(f\"  Observations: {results.data_period.get('observations', 'N/A')}\")\n",
    "        \n",
    "        # Hypothesis-specific results\n",
    "        if i == 1:\n",
    "            threshold_detected = results.main_result.get('threshold_detected', False)\n",
    "            print(f\"  Threshold detected: {threshold_detected}\")\n",
    "            if threshold_detected:\n",
    "                print(f\"  Threshold value: {results.main_result.get('threshold_value', 'N/A'):.4f}\")\n",
    "        elif i == 2:\n",
    "            investment_response = results.main_result.get('investment_response_detected', False)\n",
    "            print(f\"  Investment response: {investment_response}\")\n",
    "        elif i == 3:\n",
    "            spillover_effects = results.main_result.get('spillover_effects_detected', False)\n",
    "            print(f\"  Spillover effects: {spillover_effects}\")\n",
    "    else:\n",
    "        print(f\"  âœ— Analysis failed: {results.main_result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Custom Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom visualization dashboard\n",
    "def create_custom_dashboard(data, results_dict):\n",
    "    \"\"\"\n",
    "    Create a comprehensive dashboard for all three hypotheses\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(20, 16))\n",
    "    \n",
    "    # Create grid layout\n",
    "    gs = fig.add_gridspec(4, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Row 1: Key variables for each hypothesis\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.plot(data.dates, data.long_term_yields, 'b-', linewidth=2)\n",
    "    ax1.set_title('H1: Long-term Yields', fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.plot(data.dates, data.private_investment, 'g-', linewidth=2)\n",
    "    ax2.set_title('H2: Private Investment', fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax3.plot(data.dates, data.exchange_rate, 'r-', linewidth=2)\n",
    "    ax3.set_title('H3: Exchange Rate', fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Row 2: Threshold analysis (H1)\n",
    "    ax4 = fig.add_subplot(gs[1, :])\n",
    "    \n",
    "    h1_results = results_dict.get('Hypothesis 1')\n",
    "    if h1_results and 'error' not in h1_results.main_result:\n",
    "        threshold_detected = h1_results.main_result.get('threshold_detected', False)\n",
    "        \n",
    "        # Scatter plot: threshold variable vs dependent variable\n",
    "        ax4.scatter(data.debt_service_burden, data.long_term_yields, alpha=0.6, s=50)\n",
    "        \n",
    "        if threshold_detected:\n",
    "            threshold_value = h1_results.main_result.get('threshold_value')\n",
    "            ax4.axvline(threshold_value, color='red', linestyle='--', linewidth=2, \n",
    "                       label=f'Threshold: {threshold_value:.3f}')\n",
    "            ax4.legend()\n",
    "        \n",
    "        ax4.set_xlabel('Debt Service Burden')\n",
    "        ax4.set_ylabel('Long-term Yields')\n",
    "        ax4.set_title('H1: Threshold Analysis', fontweight='bold')\n",
    "    else:\n",
    "        ax4.text(0.5, 0.5, 'H1 Analysis Failed', ha='center', va='center', \n",
    "                transform=ax4.transAxes, fontsize=14)\n",
    "    \n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Row 3: Investment dynamics (H2)\n",
    "    ax5 = fig.add_subplot(gs[2, 0])\n",
    "    ax5.plot(data.dates, data.qe_intensity, 'orange', linewidth=2, label='QE Intensity')\n",
    "    ax5.set_title('H2: QE Intensity', fontweight='bold')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax6 = fig.add_subplot(gs[2, 1])\n",
    "    ax6.plot(data.dates, data.market_distortions, 'purple', linewidth=2, label='Market Distortions')\n",
    "    ax6.set_title('H2: Market Distortions', fontweight='bold')\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax7 = fig.add_subplot(gs[2, 2])\n",
    "    ax7.plot(data.dates, data.interest_rate_channel, 'brown', linewidth=2, label='Interest Rate Channel')\n",
    "    ax7.set_title('H2: Interest Rate Channel', fontweight='bold')\n",
    "    ax7.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Row 4: International effects (H3)\n",
    "    ax8 = fig.add_subplot(gs[3, 0])\n",
    "    ax8.plot(data.dates, data.foreign_bond_holdings, 'cyan', linewidth=2)\n",
    "    ax8.set_title('H3: Foreign Bond Holdings', fontweight='bold')\n",
    "    ax8.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax9 = fig.add_subplot(gs[3, 1])\n",
    "    ax9.plot(data.dates, data.inflation_measures, 'magenta', linewidth=2)\n",
    "    ax9.set_title('H3: Inflation Measures', fontweight='bold')\n",
    "    ax9.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax10 = fig.add_subplot(gs[3, 2])\n",
    "    ax10.plot(data.dates, data.capital_flows, 'gray', linewidth=2)\n",
    "    ax10.set_title('H3: Capital Flows', fontweight='bold')\n",
    "    ax10.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('QEIR Framework - Custom Analysis Dashboard', \n",
    "                 fontsize=20, fontweight='bold', y=0.98)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create dashboard\n",
    "results_dict = {\n",
    "    'Hypothesis 1': h1_results,\n",
    "    'Hypothesis 2': h2_results,\n",
    "    'Hypothesis 3': h3_results\n",
    "}\n",
    "\n",
    "dashboard_fig = create_custom_dashboard(custom_data, results_dict)\n",
    "plt.show()\n",
    "\n",
    "print(\"Custom dashboard created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Custom Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive results summary\n",
    "def create_results_summary(results_dict, data_metadata=None):\n",
    "    \"\"\"\n",
    "    Create a comprehensive summary of all hypothesis test results\n",
    "    \"\"\"\n",
    "    summary = {\n",
    "        'analysis_timestamp': datetime.now().isoformat(),\n",
    "        'data_info': data_metadata or {},\n",
    "        'hypothesis_results': {},\n",
    "        'overall_assessment': {}\n",
    "    }\n",
    "    \n",
    "    successful_tests = 0\n",
    "    total_tests = len(results_dict)\n",
    "    \n",
    "    for hyp_name, results in results_dict.items():\n",
    "        hyp_summary = {\n",
    "            'status': 'success' if 'error' not in results.main_result else 'failed',\n",
    "            'observations': results.data_period.get('observations', 0),\n",
    "            'period': f\"{results.data_period.get('start_date')} to {results.data_period.get('end_date')}\"\n",
    "        }\n",
    "        \n",
    "        if 'error' not in results.main_result:\n",
    "            successful_tests += 1\n",
    "            \n",
    "            # Extract key findings based on hypothesis\n",
    "            if 'Hypothesis 1' in hyp_name:\n",
    "                hyp_summary['threshold_detected'] = results.main_result.get('threshold_detected', False)\n",
    "                if hyp_summary['threshold_detected']:\n",
    "                    hyp_summary['threshold_value'] = results.main_result.get('threshold_value')\n",
    "                    hyp_summary['statistical_significance'] = results.statistical_significance.get('structural_break_significant', False)\n",
    "            \n",
    "            elif 'Hypothesis 2' in hyp_name:\n",
    "                hyp_summary['investment_response'] = results.main_result.get('investment_response_detected', False)\n",
    "                hyp_summary['local_projections_fitted'] = results.main_result.get('local_projections_fitted', False)\n",
    "                hyp_summary['iv_fitted'] = results.main_result.get('iv_fitted', False)\n",
    "            \n",
    "            elif 'Hypothesis 3' in hyp_name:\n",
    "                hyp_summary['spillover_effects'] = results.main_result.get('spillover_effects_detected', False)\n",
    "                hyp_summary['variables_analyzed'] = results.main_result.get('variables_analyzed', 0)\n",
    "                \n",
    "                # Add correlation information if available\n",
    "                if results.statistical_significance:\n",
    "                    hyp_summary['correlations'] = {\n",
    "                        'foreign_exchange': results.statistical_significance.get('foreign_exchange_correlation'),\n",
    "                        'inflation_exchange': results.statistical_significance.get('inflation_exchange_correlation')\n",
    "                    }\n",
    "        else:\n",
    "            hyp_summary['error'] = results.main_result['error']\n",
    "        \n",
    "        summary['hypothesis_results'][hyp_name] = hyp_summary\n",
    "    \n",
    "    # Overall assessment\n",
    "    summary['overall_assessment'] = {\n",
    "        'success_rate': successful_tests / total_tests,\n",
    "        'successful_tests': successful_tests,\n",
    "        'total_tests': total_tests,\n",
    "        'data_quality': 'synthetic' if data_metadata and data_metadata.get('source') == 'custom_synthetic_data' else 'real'\n",
    "    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Create results summary\n",
    "results_summary = create_results_summary(results_dict, custom_data.metadata)\n",
    "\n",
    "# Display summary\n",
    "print(\"COMPREHENSIVE RESULTS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nAnalysis Timestamp: {results_summary['analysis_timestamp']}\")\n",
    "print(f\"Data Source: {results_summary['data_info'].get('source', 'Unknown')}\")\n",
    "print(f\"Success Rate: {results_summary['overall_assessment']['success_rate']:.1%}\")\n",
    "print(f\"Successful Tests: {results_summary['overall_assessment']['successful_tests']}/{results_summary['overall_assessment']['total_tests']}\")\n",
    "\n",
    "print(\"\\nHypothesis Results:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for hyp_name, hyp_results in results_summary['hypothesis_results'].items():\n",
    "    print(f\"\\n{hyp_name}:\")\n",
    "    print(f\"  Status: {hyp_results['status'].upper()}\")\n",
    "    print(f\"  Observations: {hyp_results['observations']}\")\n",
    "    print(f\"  Period: {hyp_results['period']}\")\n",
    "    \n",
    "    if hyp_results['status'] == 'success':\n",
    "        if 'threshold_detected' in hyp_results:\n",
    "            print(f\"  Threshold Detected: {hyp_results['threshold_detected']}\")\n",
    "            if hyp_results['threshold_detected']:\n",
    "                print(f\"  Threshold Value: {hyp_results['threshold_value']:.4f}\")\n",
    "                print(f\"  Statistically Significant: {hyp_results.get('statistical_significance', 'N/A')}\")\n",
    "        \n",
    "        if 'investment_response' in hyp_results:\n",
    "            print(f\"  Investment Response: {hyp_results['investment_response']}\")\n",
    "            print(f\"  Local Projections Fitted: {hyp_results['local_projections_fitted']}\")\n",
    "        \n",
    "        if 'spillover_effects' in hyp_results:\n",
    "            print(f\"  Spillover Effects: {hyp_results['spillover_effects']}\")\n",
    "            if 'correlations' in hyp_results:\n",
    "                corrs = hyp_results['correlations']\n",
    "                print(f\"  Foreign-Exchange Correlation: {corrs.get('foreign_exchange', 'N/A')}\")\n",
    "    else:\n",
    "        print(f\"  Error: {hyp_results.get('error', 'Unknown error')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export Results for External Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to various formats\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"custom_analysis_outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 1. Export summary to JSON\n",
    "def export_to_json(data, filename):\n",
    "    \"\"\"Export data to JSON with proper serialization\"\"\"\n",
    "    def json_serializer(obj):\n",
    "        if isinstance(obj, (pd.Timestamp, pd.DatetimeIndex)):\n",
    "            return obj.isoformat()\n",
    "        elif isinstance(obj, pd.Series):\n",
    "            return obj.to_dict()\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif hasattr(obj, '__dict__'):\n",
    "            return obj.__dict__\n",
    "        return str(obj)\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f, indent=2, default=json_serializer)\n",
    "\n",
    "# Export results summary\n",
    "export_to_json(results_summary, f\"{output_dir}/results_summary.json\")\n",
    "print(f\"âœ“ Results summary exported to {output_dir}/results_summary.json\")\n",
    "\n",
    "# 2. Export data to CSV\n",
    "data_df = pd.DataFrame({\n",
    "    'date': custom_data.dates,\n",
    "    'central_bank_reaction': custom_data.central_bank_reaction,\n",
    "    'confidence_effects': custom_data.confidence_effects,\n",
    "    'debt_service_burden': custom_data.debt_service_burden,\n",
    "    'long_term_yields': custom_data.long_term_yields,\n",
    "    'qe_intensity': custom_data.qe_intensity,\n",
    "    'private_investment': custom_data.private_investment,\n",
    "    'market_distortions': custom_data.market_distortions,\n",
    "    'interest_rate_channel': custom_data.interest_rate_channel,\n",
    "    'foreign_bond_holdings': custom_data.foreign_bond_holdings,\n",
    "    'exchange_rate': custom_data.exchange_rate,\n",
    "    'inflation_measures': custom_data.inflation_measures,\n",
    "    'capital_flows': custom_data.capital_flows\n",
    "})\n",
    "\n",
    "data_df.to_csv(f\"{output_dir}/hypothesis_data.csv\", index=False)\n",
    "print(f\"âœ“ Data exported to {output_dir}/hypothesis_data.csv\")\n",
    "\n",
    "# 3. Save dashboard figure\n",
    "dashboard_fig.savefig(f\"{output_dir}/analysis_dashboard.png\", \n",
    "                     dpi=300, bbox_inches='tight', facecolor='white')\n",
    "print(f\"âœ“ Dashboard saved to {output_dir}/analysis_dashboard.png\")\n",
    "\n",
    "# 4. Create summary report\n",
    "def create_text_report(results_summary, filename):\n",
    "    \"\"\"Create a human-readable text report\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"QEIR FRAMEWORK - CUSTOM ANALYSIS REPORT\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Analysis Date: {results_summary['analysis_timestamp']}\\n\")\n",
    "        f.write(f\"Data Source: {results_summary['data_info'].get('source', 'Unknown')}\\n\")\n",
    "        f.write(f\"Success Rate: {results_summary['overall_assessment']['success_rate']:.1%}\\n\\n\")\n",
    "        \n",
    "        f.write(\"HYPOTHESIS TEST RESULTS\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\\n\")\n",
    "        \n",
    "        for hyp_name, hyp_results in results_summary['hypothesis_results'].items():\n",
    "            f.write(f\"{hyp_name}:\\n\")\n",
    "            f.write(f\"  Status: {hyp_results['status'].upper()}\\n\")\n",
    "            f.write(f\"  Observations: {hyp_results['observations']}\\n\")\n",
    "            f.write(f\"  Period: {hyp_results['period']}\\n\")\n",
    "            \n",
    "            if hyp_results['status'] == 'success':\n",
    "                if 'threshold_detected' in hyp_results:\n",
    "                    f.write(f\"  Key Finding: Threshold {'detected' if hyp_results['threshold_detected'] else 'not detected'}\\n\")\n",
    "                elif 'investment_response' in hyp_results:\n",
    "                    f.write(f\"  Key Finding: Investment response {'detected' if hyp_results['investment_response'] else 'not detected'}\\n\")\n",
    "                elif 'spillover_effects' in hyp_results:\n",
    "                    f.write(f\"  Key Finding: Spillover effects {'detected' if hyp_results['spillover_effects'] else 'not detected'}\\n\")\n",
    "            else:\n",
    "                f.write(f\"  Error: {hyp_results.get('error', 'Unknown error')}\\n\")\n",
    "            \n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"\\nEND OF REPORT\\n\")\n",
    "\n",
    "create_text_report(results_summary, f\"{output_dir}/analysis_report.txt\")\n",
    "print(f\"âœ“ Text report saved to {output_dir}/analysis_report.txt\")\n",
    "\n",
    "print(f\"\\nAll outputs saved to '{output_dir}/' directory\")\n",
    "print(\"Files created:\")\n",
    "for file in os.listdir(output_dir):\n",
    "    print(f\"  - {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated advanced customization techniques for the QEIR framework:\n",
    "\n",
    "### Key Techniques Covered:\n",
    "\n",
    "1. **Custom Data Integration:**\n",
    "   - Creating `HypothesisData` objects with your own data\n",
    "   - Synthetic data generation for testing\n",
    "   - Integration with external data sources\n",
    "\n",
    "2. **Custom Analysis Workflows:**\n",
    "   - Running hypothesis tests with custom data\n",
    "   - Handling analysis results programmatically\n",
    "   - Error handling and validation\n",
    "\n",
    "3. **Advanced Visualization:**\n",
    "   - Multi-panel dashboard creation\n",
    "   - Custom plotting functions\n",
    "   - Publication-quality figure generation\n",
    "\n",
    "4. **Results Processing:**\n",
    "   - Comprehensive results summarization\n",
    "   - Structured data extraction\n",
    "   - Cross-hypothesis comparison\n",
    "\n",
    "5. **Export and Integration:**\n",
    "   - JSON export for programmatic use\n",
    "   - CSV export for spreadsheet analysis\n",
    "   - High-resolution figure export\n",
    "   - Human-readable report generation\n",
    "\n",
    "### Applications:\n",
    "\n",
    "- **Research Projects:** Integrate with your own datasets\n",
    "- **Policy Analysis:** Custom scenarios and simulations\n",
    "- **Academic Papers:** Publication-ready outputs\n",
    "- **Presentations:** Dashboard-style visualizations\n",
    "- **Further Analysis:** Export data for other tools\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Replace synthetic data with your actual datasets\n",
    "2. Customize visualizations for your specific needs\n",
    "3. Integrate with your existing analysis workflows\n",
    "4. Use exported results in other tools (R, Stata, Excel)\n",
    "5. Combine with the other notebooks for comprehensive analysis\n",
    "\n",
    "This approach allows you to leverage the QEIR framework's robust econometric methods while maintaining full control over your data and analysis workflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}